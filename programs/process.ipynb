{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5deb5-6f78-46f1-acde-ee478e32ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fde8a1a3-979d-4785-a269-8691c59c6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hocr import Hocr\n",
    "from tfFromTsv import convert, loadTf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c71c39-86c3-46c7-8c4f-7e1c1282bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = Hocr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2566e2c2-22df-4818-8410-ecad80d3e55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplifying HOCR source\n",
      "All lines recognized\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "H.simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945b03f1-5bf2-4f2b-8dc3-2fd6cd623c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading HOCR simplified source\n",
      "     18 spaces with width  0\n",
      "    147 spaces with width 10\n",
      "  13438 spaces with width 20\n",
      "  12243 spaces with width 30\n",
      "  53049 spaces with width 40\n",
      "  85050 spaces with width 50\n",
      "  13765 spaces with width 60\n",
      "  38341 spaces with width 70\n",
      "   2801 spaces with width 80\n",
      "    722 spaces with width 90\n",
      "     71 spaces with width 100\n",
      "     23 spaces with width 110\n",
      "      7 spaces with width 120\n",
      "      4 spaces with width 140\n",
      "      6 spaces with width 150\n",
      "      1 spaces with width 160\n",
      "      4 spaces with width 190\n",
      "    737 spaces with width 200\n",
      "Inhibited 58 word boundaries after a thin space of <= 9 px\n",
      "Statistics:\n",
      "page      :     529 x\n",
      "photo     :       0 x\n",
      "table     :       0 x\n",
      "tr        :       0 x\n",
      "td        :       0 x\n",
      "area      :    1785 x\n",
      "para      :    6840 x\n",
      "line      :   24052 x\n",
      "word      :  240148 x\n",
      "char      : 1528934 x minus 58 = 1528876\n",
      "Is this equal to the resulting number of charachter records? True\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "H.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b720bfb-8cfb-4bdf-8b4c-d63c13c32808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking characters into words\n",
      "240148 raw words\n",
      "55 word joins:\n",
      "line      17: bef + ore \n",
      "line     435: any + where \n",
      "line     531: half + of \n",
      "line    1015: dagelij + ksche \n",
      "line    1017: o + f \n",
      "line    1661: Par + sta, \n",
      "line    3780: bat + talie\n",
      "line    4390: uyt + val \n",
      "line   10838: on + verhandelde\n",
      "line   16922: daer + van \n",
      "line   20109: uyt + vallen \n",
      "line   20569: namen + tlyck \n",
      "line   20990: voornamen + tlyck \n",
      "line   22158: schoof + en \n",
      "line   24399: vertreek + t  \n",
      "line   24641: Ha + tips \n",
      "line   34538: Sant + voort, \n",
      "line   34826: Buy + ren \n",
      "line   44239: namen + tlyck \n",
      "line   48179: f + ondergebracht\n",
      "line   52984: soo + veel \n",
      "line   55549: (uy + tgesondert \n",
      "line   57453: by + gelegene \n",
      "line   61031: brieff + ken \n",
      "line   61414: veltovers + ten \n",
      "line   68286: f + synen\n",
      "line   74551: Geinven + teerde \n",
      "line   83144: gearriveerrt + jacht\n",
      "line   87517: Ad + vis \n",
      "line   90185: ca + villatien \n",
      "line   96288: sieck + te,\n",
      "line   96357: uy + tgeseth \n",
      "line  103309: musea + ten \n",
      "line  122519: ge + voert\n",
      "line  128547: stond + t.\n",
      "line  129152: harten + vlees, \n",
      "line  135449: Pot + tra \n",
      "line  152611: 6^1 + ^ \n",
      "line  154666: ca + vel \n",
      "line  155087: ver + treek \n",
      "line  164943: f + samen \n",
      "line  166554: overhey + t \n",
      "line  168364: party + e\n",
      "line  177286: Gat + ton, \n",
      "line  178680: al + tyt \n",
      "line  183633: buy + ten, \n",
      "line  186985: den + \"president \n",
      "line  188176: swar + te \n",
      "line  195865: proffy + t \n",
      "line  204502: May + f. \n",
      "line  204635: Pa + te \n",
      "line  207378: uyt + voerende \n",
      "line  207612: noch + te \n",
      "line  212262: party + e \n",
      "line  222117: f + sampt \n"
     ]
    }
   ],
   "source": [
    "H.wordify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6681a7-b37b-4258-a727-dbb8888f57aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 5 front pages and 'Digitized by Google'\n",
      "Missed 'Digitized by Google' 0 x\n",
      "Deleted 'Digitized by Google' 524 x\n",
      "Deleted the header line of 524 pages\n",
      "236399 words\n",
      "Not counting 3749 skipped words\n",
      "Did all other words make it into the word records? True\n",
      "See /Users/dirk/github/Dans-labs/clariah-dr/diagnostics/headlines.tsv for removed header lines\n"
     ]
    }
   ],
   "source": [
    "H.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e66bd4-e990-4147-8e33-4c7395e667bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing word file as tsv\n"
     ]
    }
   ],
   "source": [
    "H.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7739c38-68a7-415e-b1f2-6f81b0682b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 9.1.6\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "0 features found and 0 ignored\n",
      "  0.00s Warp feature \"otype\" not found in\n",
      "~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1/\n",
      "  0.00s Warp feature \"oslots\" not found in\n",
      "~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1/\n",
      "  0.00s Warp feature \"otext\" not found. Working without Text-API\n",
      "\n",
      "  0.00s Importing data from walking through the source ...\n",
      "   |     0.00s Preparing metadata... \n",
      "   |     0.00s No structure nodes will be set up\n",
      "   |   SECTION   TYPES:    volume, page, line\n",
      "   |   SECTION   FEATURES: n, n, n\n",
      "   |   STRUCTURE TYPES:    \n",
      "   |   STRUCTURE FEATURES: \n",
      "   |   TEXT      FEATURES:\n",
      "   |      |   text-orig-full       letters, punc\n",
      "   |     0.00s OK\n",
      "   |     0.00s Following director... \n",
      "   |     1.50s \"edge\" actions: 0\n",
      "   |     1.50s \"feature\" actions: 264541\n",
      "   |     1.50s \"node\" actions: 28143\n",
      "   |     1.50s \"resume\" actions: 0\n",
      "   |     1.50s \"slot\" actions: 236398\n",
      "   |     1.50s \"terminate\" actions: 28146\n",
      "   |      22444 x \"line\" node \n",
      "   |        518 x \"page\" node \n",
      "   |       5180 x \"para\" node \n",
      "   |          1 x \"volume\" node \n",
      "   |     236398 x \"word\" node  = slot type\n",
      "   |     264541 nodes of all types\n",
      "   |     1.53s OK\n",
      "   |     0.00s checking for nodes and edges ... \n",
      "   |     0.00s OK\n",
      "   |     0.00s checking features ... \n",
      "   |     0.01s OK\n",
      "   |     0.00s reordering nodes ...\n",
      "   |     0.06s Sorting 22444 nodes of type \"line\"\n",
      "   |     0.11s Sorting 518 nodes of type \"page\"\n",
      "   |     0.13s Sorting 5180 nodes of type \"para\"\n",
      "   |     0.16s Sorting 1 nodes of type \"volume\"\n",
      "   |     0.17s Max node = 264541\n",
      "   |     0.17s OK\n",
      "   |     0.00s reassigning feature values ...\n",
      "   |      |    -0.00s node feature \"letters\" with 236398 nodes\n",
      "   |      |     0.05s node feature \"n\" with 28143 nodes\n",
      "   |      |     0.06s node feature \"punc\" with 236398 nodes\n",
      "   |     0.15s OK\n",
      "  0.00s Exporting 4 node and 1 edge and 1 config features to ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1:\n",
      "  0.00s VALIDATING oslots feature\n",
      "  0.04s VALIDATING oslots feature\n",
      "  0.04s maxSlot=     236398\n",
      "  0.04s maxNode=     264541\n",
      "  0.04s OK: oslots is valid\n",
      "   |     0.24s T letters              to ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "   |     0.03s T n                    to ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "   |     0.07s T otype                to ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "   |     0.23s T punc                 to ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "   |     0.15s T oslots               to ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "   |     0.00s M otext                to ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "  0.77s Exported 4 node features and 1 edge features and 1 config features to ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af83ba09-b6d9-41bb-8f39-1458b4213a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 9.1.6\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "6 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.09s T otype                from ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "   |     0.54s T oslots               from ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.40s T punc                 from ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "   |     0.04s T n                    from ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "   |     0.48s T letters              from ~/github/Dans-labs/clariah-dr/tf/daghregister/001/0.1\n",
      "   |      |     0.02s C __levels__           from otype, oslots, otext\n",
      "   |      |     1.25s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.09s C __rank__             from otype, __order__\n",
      "   |      |     1.36s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     0.08s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     0.85s C __boundary__         from otype, oslots, __rank__\n",
      "   |      |     0.07s C __sections__         from otype, oslots, otext, __levUp__, __levels__, n, n, n\n",
      "  5.30s All features loaded/computed - for details use TF.isLoaded()\n",
      "max node = 264541\n",
      "Frequencies of words\n",
      "  7728 x ende\n",
      "  5888 x van\n",
      "  4530 x de\n",
      "  4383 x te\n",
      "  3883 x met\n",
      "  3449 x den\n",
      "  3017 x een\n",
      "  2374 x dat\n",
      "  2316 x in\n",
      "  1816 x syn\n",
      "  1756 x op\n",
      "  1666 x \n",
      "  1631 x als\n",
      "  1557 x niet\n",
      "  1557 x was\n",
      "  1431 x nae\n",
      "  1308 x tot\n",
      "  1268 x die\n",
      "  1229 x voor\n",
      "  1177 x het\n"
     ]
    }
   ],
   "source": [
    "loadTf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98382f43-393b-418d-a934-ee03c049efad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
